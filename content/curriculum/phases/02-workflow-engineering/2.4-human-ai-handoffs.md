---
id: "2.4-human-ai-handoffs"
title: "Human-AI Handoffs"
phase: 2
module: 4
estimatedMinutes: 10
concepts:
  - handoff-design
  - escalation-paths
  - human-oversight
  - automation-boundaries
bloomLevel: "apply"
---

# Human-AI Handoffs

## WHY This Matters

The most dangerous AI workflows are the ones where humans are nominally "in the loop" but have no practical ability to intervene meaningfully. Effective human-AI collaboration requires:

- **Clear boundaries** between AI and human responsibility
- **Meaningful checkpoints** where humans can actually add value
- **Escalation paths** when AI reaches its limits
- **Context preservation** so humans understand what AI did

Get handoffs wrong, and you get rubber-stamp humans or chaos when things go wrong.

---

## WHAT You Need to Know

### Handoff Design Principles

:::concept[handoff-design]
A **handoff** is any point where control or responsibility transfers between AI and human. Well-designed handoffs:

1. **Preserve context**: Human knows what AI did and why
2. **Enable verification**: Human can assess AI's work
3. **Allow intervention**: Human can modify, reject, or redirect
4. **Define responsibility**: Clear who owns the outcome
5. **Support escalation**: Path exists when AI can't proceed
:::

**Handoff types:**

| Type | Direction | Example |
|------|-----------|---------|
| **Initiation** | Human → AI | User submits task to AI system |
| **Checkpoint** | AI → Human → AI | AI pauses for approval, then continues |
| **Completion** | AI → Human | AI delivers output for human use |
| **Escalation** | AI → Human | AI can't complete, needs human help |
| **Override** | Human → AI | Human intervenes mid-process |

### The Context Package

When AI hands off to human, include:

```
CONTEXT PACKAGE
├── What was requested (original input)
├── What AI did (steps taken)
├── What AI produced (output/draft)
├── Confidence level (AI's self-assessment)
├── Flagged concerns (anything uncertain)
├── Options if applicable (alternatives considered)
└── What human needs to do (clear next action)
```

**Example handoff message:**

> **Task**: Draft response to customer complaint #4521
>
> **Summary**: Customer upset about delayed shipment. Requested refund.
>
> **Draft response**: [AI-generated response]
>
> **Confidence**: Medium (85%)
>
> **Flags**:
> - Customer mentions legal action (escalation policy may apply)
> - Account shows 3 prior complaints (retention risk)
>
> **Your action**: Review draft and decide on compensation offer

### Escalation Path Design

:::concept[escalation]
**Escalation** occurs when AI recognizes it shouldn't proceed autonomously. Triggers include:

- **Uncertainty**: AI isn't confident in the right answer
- **Policy**: Situation matches escalation rules
- **Anomaly**: Input is outside normal patterns
- **Failure**: AI can't complete the task
- **Stakes**: Outcome consequences exceed AI's authority
:::

**Escalation matrix:**

| Trigger | Response | Human Action |
|---------|----------|--------------|
| Low confidence (<70%) | Flag for review | Verify before sending |
| Policy keyword detected | Hard stop | Human must decide |
| Multiple valid options | Present choices | Human selects |
| Task failure | Report with diagnosis | Human troubleshoots |
| High-value customer | Require approval | Human approves |

### Human Oversight Patterns

**Pattern 1: Pre-flight approval**
```
Human defines task → AI executes → Human uses output
```
Best for: Routine tasks, experienced operators

**Pattern 2: Checkpoint approval**
```
AI proposes → Human approves → AI executes
```
Best for: Consequential actions, early adoption

**Pattern 3: Post-hoc review**
```
AI executes → Human reviews sample → Feedback loop
```
Best for: High-volume, lower-stakes

**Pattern 4: Exception-based**
```
AI executes normally → Escalates exceptions → Human handles edge cases
```
Best for: Mature workflows, clear rules

### Designing Meaningful Checkpoints

**Bad checkpoint** (rubber stamp):
- Human sees: "AI did something. OK?"
- Human can: Click "approve" or "reject"
- Human knows: Nothing useful
- Result: Automatic approval, no real oversight

**Good checkpoint**:
- Human sees: Context, draft, confidence, concerns
- Human can: Approve, edit, reject, escalate, redirect
- Human knows: What AI did, why, and risk areas
- Result: Genuine review, meaningful intervention

---

## HOW to Apply This

### Exercise: Design a Handoff System

:::exercise[handoff-design-exercise]
**Scenario**: You're designing an AI system to handle initial customer support inquiries. The system should:
- Classify incoming tickets by type and urgency
- Draft initial responses
- Identify tickets needing human attention
- Route complex issues to appropriate teams

**Design the handoff system:**

1. **Map all handoff points**
   - Where does AI receive human input?
   - Where should AI pause for approval?
   - Where does AI deliver final output?

2. **Define escalation triggers**
   - What situations should always go to humans?
   - What confidence threshold requires review?
   - What keywords/patterns trigger escalation?

3. **Design the context package**
   - What information should AI provide at each handoff?
   - What does the human need to make a good decision?

4. **Create the checkpoint interface**
   - What options does the human have?
   - How does human feedback improve future performance?

5. **Plan for failures**
   - What happens if AI crashes mid-task?
   - How is work recovered?
   - Who is notified?
:::

### Handoff Anti-Patterns

| Anti-Pattern | Problem | Solution |
|--------------|---------|----------|
| **Rubber stamp** | Human approves without review | Make review necessary and fast |
| **Context loss** | Human doesn't know what AI did | Include comprehensive context |
| **Hidden escalation** | AI decides when to escalate | Clear, auditable rules |
| **Escalation overload** | Too many escalations | Tune triggers, improve AI |
| **No return path** | Human can't redirect AI | Enable mid-workflow intervention |
| **Blame ambiguity** | Unclear who's responsible | Explicit ownership at each stage |

### Checklist for Handoff Design

| Element | Question |
|---------|----------|
| **Triggers** | When does handoff occur? |
| **Context** | What information transfers? |
| **Actions** | What can the recipient do? |
| **Responsibility** | Who owns the outcome? |
| **Escalation** | What if recipient can't handle it? |
| **Logging** | Is the handoff recorded? |
| **Recovery** | What if handoff fails? |

### Self-Check

:::checklist[module-2.4-complete]
- [ ] I can identify handoff points in a workflow
- [ ] I understand different types of handoffs
- [ ] I can design context packages for handoffs
- [ ] I know how to set up escalation triggers
- [ ] I can recognize and fix handoff anti-patterns
:::

---

## Phase 2 Complete!

You've mastered Workflow Engineering fundamentals. Before moving to Phase 3, complete:

**Lab 3: Workflow Mapping** — Document a real workflow and identify AI integration opportunities

**Lab 4: Quality Gate Design** — Create a quality assurance system for an AI workflow

**Phase 2 Deliverable: Workflow Automation Proposal** — Document a real workflow with AI integration opportunities, including ROI analysis
