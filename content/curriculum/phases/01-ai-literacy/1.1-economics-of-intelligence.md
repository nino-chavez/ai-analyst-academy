---
id: "1.1-economics-of-intelligence"
title: "Economics of Intelligence"
phase: 1
module: 1
estimatedMinutes: 12
concepts:
  - tokens
  - cost-hierarchy
  - context-windows
  - rate-limits
bloomLevel: "understand"
---

# Economics of Intelligence

## WHY This Matters

Every AI interaction has a cost. Understanding the economics of AI systems transforms you from a casual user into a strategic operator who can:

- **Budget effectively** for AI-powered projects
- **Optimize prompts** for cost efficiency without sacrificing quality
- **Choose the right model** for each task
- **Predict costs** before committing to large-scale operations

The difference between a $50/month AI budget and a $5,000/month budget often isn't the work being done—it's how intelligently the work is structured.

---

## WHAT You Need to Know

### Tokens: The Currency of AI

:::concept[tokens]
A **token** is the fundamental unit AI models use to process text. In English, one token roughly equals:
- 4 characters
- 0.75 words
- About 3/4 of a typical word

Examples:
- "Hello" = 1 token
- "Hello, world!" = 4 tokens
- A typical email (200 words) ≈ 270 tokens
- This entire module ≈ 2,000 tokens
:::

**Why tokens matter:**
1. **Pricing** is based on tokens (input + output)
2. **Context windows** have token limits
3. **Response quality** can degrade as context fills up

### The Cost Hierarchy

Different AI capabilities have dramatically different costs:

| Capability | Relative Cost | Example Use |
|------------|---------------|-------------|
| Text generation (small model) | $ | Quick summaries, simple Q&A |
| Text generation (large model) | $$ | Complex reasoning, nuanced writing |
| Code generation | $$$ | Software development, debugging |
| Image generation | $$$$ | Visual content creation |
| Video generation | $$$$$ | Marketing materials, demos |

### Context Window Economics

:::concept[context-window]
The **context window** is the total amount of text (measured in tokens) that an AI can "see" at once—including your prompt AND its response.

Think of it like RAM for a conversation:
- **GPT-4o**: 128K tokens (~96,000 words)
- **Claude 3.5 Sonnet**: 200K tokens (~150,000 words)
- **Gemini 1.5 Pro**: 1M+ tokens (~750,000 words)
:::

**Key insight**: Larger context windows cost more per interaction but enable:
- Analyzing entire documents at once
- Maintaining longer conversation history
- Processing multiple sources simultaneously

### Rate Limits and Throughput

Even with unlimited budget, you'll hit rate limits:

| Limit Type | What It Controls | Business Impact |
|------------|------------------|-----------------|
| Requests per minute (RPM) | How often you can call the API | Affects real-time applications |
| Tokens per minute (TPM) | Total throughput | Affects batch processing speed |
| Tokens per day (TPD) | Daily capacity | Affects large-scale operations |

**Pro tip**: Higher-tier API plans have higher rate limits, not just lower costs.

---

## HOW to Apply This

### Exercise: Calculate Your AI Costs

:::exercise[cost-calculation]
**Scenario**: You want to analyze customer feedback. You have:
- 5,000 customer reviews (average 150 words each)
- Goal: Sentiment analysis + key themes extraction

**Calculate**:
1. Total input tokens (reviews + prompt)
2. Estimated output tokens (analysis per review)
3. Total cost using GPT-4o pricing ($2.50/1M input, $10/1M output)

**Hint**:
- 5,000 reviews × 150 words × 1.33 tokens/word = input tokens
- Assume ~100 tokens output per review analysis
:::

### Quick Reference: Cost Optimization Strategies

| Strategy | Savings | Trade-off |
|----------|---------|-----------|
| Use smaller models for simple tasks | 50-90% | May miss nuance |
| Batch similar requests | 20-40% | Increased latency |
| Cache common responses | 30-70% | Staleness risk |
| Truncate unnecessary context | 10-30% | May lose relevant info |
| Use structured output formats | 15-25% | Less natural language |

### Self-Check

:::checklist[module-1.1-complete]
- [ ] I can estimate token counts for text content
- [ ] I understand the cost hierarchy of AI capabilities
- [ ] I know what context windows are and why they matter
- [ ] I can calculate approximate costs for an AI project
- [ ] I understand rate limits and their business implications
:::

---

## Up Next

In **Module 1.2: Context and Memory**, you'll learn how AI systems manage information across conversations—and why "memory" is both powerful and limited.
