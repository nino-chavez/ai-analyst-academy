---
id: "1.2-context-and-memory"
title: "Context and Memory"
phase: 1
module: 2
estimatedMinutes: 10
concepts:
  - context-window
  - system-prompts
  - conversation-history
  - context-injection
bloomLevel: "understand"
---

# Context and Memory

## WHY This Matters

AI models don't have persistent memory the way humans do. Every interaction starts fresh—unless you deliberately provide context. Understanding how AI "remembers" is crucial because:

- **Quality depends on context**: The same question with different context produces dramatically different answers
- **Consistency requires structure**: Without explicit context management, AI responses drift and contradict
- **Cost scales with context**: More context = more tokens = higher costs

Mastering context management is what separates effective AI operators from frustrated users.

---

## WHAT You Need to Know

### The Stateless Reality

:::concept[stateless]
AI models are fundamentally **stateless**—they don't remember previous conversations unless you explicitly include that history in your current prompt.

When you chat with ChatGPT, the interface manages this for you by sending your entire conversation history with each message. But behind the scenes, every API call is independent.
:::

**What this means in practice:**
- The AI doesn't "know" you between sessions
- Personality and preferences must be re-established each time
- Long conversations eventually hit context limits

### System Prompts: Setting the Stage

:::concept[system-prompt]
A **system prompt** is special instruction text that shapes how the AI behaves throughout a conversation. It's like giving an actor their character brief before a scene.

System prompts typically include:
- **Role definition**: "You are a financial analyst specializing in retail..."
- **Behavioral constraints**: "Always cite sources. Never make up statistics."
- **Output format**: "Respond in bullet points. Keep responses under 200 words."
- **Domain context**: Background information relevant to all interactions
:::

**Effective system prompt structure:**

```
You are [ROLE] with expertise in [DOMAIN].

Your responsibilities:
- [Primary function]
- [Secondary function]

When responding:
- [Style guideline]
- [Format requirement]
- [Constraint]

Context about the user/situation:
[Relevant background that applies to all interactions]
```

### Conversation History Management

As conversations grow, you face the **context window squeeze**:

| Conversation Length | Challenge | Strategy |
|---------------------|-----------|----------|
| Short (< 2K tokens) | None | Include full history |
| Medium (2K-10K tokens) | Cost | Summarize older exchanges |
| Long (10K+ tokens) | Quality degradation | Rolling summary + recent messages |
| Very Long (near limit) | Truncation required | Strategic pruning |

**The sliding window approach:**
1. Keep the system prompt (always)
2. Keep a running summary of key decisions/context
3. Keep the most recent 3-5 exchanges in full
4. Summarize or drop older messages

### Context Injection Patterns

:::concept[context-injection]
**Context injection** is the practice of inserting relevant information into prompts so the AI can make informed decisions without having to "know" everything.

Types of injected context:
- **User data**: "The customer's account was created 3 years ago and they've made 47 purchases"
- **Document excerpts**: "Based on section 4.2 of the policy: [relevant text]"
- **Current state**: "Current inventory: 150 units. Reorder threshold: 100 units."
- **Constraints**: "Budget remaining: $5,000. Timeline: 2 weeks."
:::

**Example transformation:**

❌ **Without context injection:**
> "Write a response to this customer complaint"

✅ **With context injection:**
> "Write a response to this customer complaint.
>
> Customer context:
> - Premium member since 2019
> - 3 previous support tickets (all resolved satisfactorily)
> - Current issue: Delayed shipment (5 days late)
> - Company policy: Offer 20% discount for delays > 3 days
>
> Complaint: [customer message]"

---

## HOW to Apply This

### Exercise: Design a Context Strategy

:::exercise[context-strategy]
**Scenario**: You're building an AI assistant for sales representatives to help them prepare for customer calls.

**Design the context structure:**
1. What goes in the system prompt? (persistent context)
2. What gets injected per-call? (dynamic context)
3. How do you handle multi-call history with the same customer?
4. What's your strategy when approaching context limits?

**Consider**:
- CRM data availability
- Call notes from previous interactions
- Product/pricing information
- Competitive intelligence
:::

### Context Management Patterns

| Pattern | Use Case | Implementation |
|---------|----------|----------------|
| **Full History** | Short, high-value conversations | Send everything |
| **Rolling Summary** | Long-running assistants | Summarize after each exchange |
| **Retrieval Augmented** | Knowledge-heavy domains | Fetch relevant docs per query |
| **Hybrid** | Complex applications | Summary + retrieved + recent |

### Common Mistakes to Avoid

| Mistake | Why It's Bad | Better Approach |
|---------|--------------|-----------------|
| Assuming AI remembers | Inconsistent results | Always provide necessary context |
| Overloading system prompt | Wasted tokens, confused behavior | Keep it focused, inject dynamic data |
| Ignoring context limits | Truncated/degraded responses | Monitor and manage proactively |
| No summarization strategy | Expensive, eventually breaks | Plan for long conversations |

### Self-Check

:::checklist[module-1.2-complete]
- [ ] I understand that AI is stateless by default
- [ ] I can write effective system prompts
- [ ] I know strategies for managing conversation history
- [ ] I can design context injection for a business scenario
- [ ] I understand trade-offs between context approaches
:::

---

## Up Next

In **Module 1.3: Providers and Models**, you'll learn how to navigate the AI landscape—comparing capabilities, costs, and use cases across major providers.
