---
id: "1.5-problem-classification"
title: "When to Use Agents vs. Simpler AI"
phase: 1
module: 5
estimatedMinutes: 12
concepts:
  - problem-classification
  - solution-spectrum
  - sharp-rough-problems
  - complexity-matching
bloomLevel: "analyze"
---

# When to Use Agents vs. Simpler AI

## WHY This Matters

The biggest waste in AI projects isn't failed agents—it's using agents when a simple prompt would suffice.

Every layer of complexity you add (chains, tools, agents, multi-agent systems) introduces:
- More failure points
- Higher latency
- Greater cost
- Harder debugging

**The goal isn't to build the most sophisticated AI system. It's to solve the problem with the minimum viable complexity.**

Knowing your problem type before you start building saves weeks of wasted effort.

---

## WHAT You Need to Know

### The AI Solution Spectrum

:::concept[solution-spectrum]
AI solutions exist on a spectrum of complexity. Each level up adds capability but also cost and fragility:

| Level | Tool | Characteristics | Example |
|-------|------|-----------------|---------|
| **0** | No AI | Deterministic, rule-based | Form validation, calculations |
| **1** | Single prompt | One-shot generation | Draft an email, summarize text |
| **2** | Prompt chain | Multi-step, sequential | Research topic → synthesize → write |
| **3** | Tool-using agent | Dynamic tool selection | Support bot that checks orders, processes refunds |
| **4** | Multi-agent system | Complex, parallel tasks | Content production pipeline with specialists |

**The 80/20 Rule:** 80% of business use cases need Level 1-2. Only 5% truly justify Level 4.
:::

### Sharp-Edged vs Rough-Edged Problems

:::concept[sharp-rough-problems]
Problems fall into two fundamental categories that determine how AI should handle them:

**Sharp-edged problems** have:
- One correct answer (or a small set of correct answers)
- Clear, objective success criteria
- Deterministic verification possible
- Examples: Math calculation, code syntax check, data validation, fact lookup

**Rough-edged problems** have:
- Multiple valid solutions
- Subjective quality criteria
- Probabilistic, "good enough" outcomes
- Examples: Content creation, strategy advice, creative work, nuanced judgment

**Why this matters:** Sharp-edged problems often don't need AI at all—code or rules work better. Rough-edged problems are where AI excels, but also where evaluation is hardest.
:::

### The Problem Classification Framework

Before building anything, run your problem through this decision tree:

```
START: What problem are you solving?
│
├─ Is there ONE correct answer?
│  │
│  ├─ YES → Can you compute it without AI?
│  │        │
│  │        ├─ YES → Use code, not AI (Level 0)
│  │        │        Example: Calculate shipping cost
│  │        │
│  │        └─ NO → Use single prompt or chain (Level 1-2)
│  │                 Example: Extract specific data from document
│  │
│  └─ NO → Does it require multiple distinct steps?
│          │
│          ├─ NO → Use single prompt (Level 1)
│          │       Example: Write a product description
│          │
│          └─ YES → Does it need dynamic decisions mid-process?
│                   │
│                   ├─ NO → Use prompt chain (Level 2)
│                   │       Example: Research → Outline → Draft → Edit
│                   │
│                   └─ YES → Does it need parallel work streams?
│                            │
│                            ├─ NO → Use single agent (Level 3)
│                            │       Example: Support bot handling varied requests
│                            │
│                            └─ YES → Use multi-agent system (Level 4)
│                                     Example: Complex research with multiple specialists
```

### Complexity Matching Examples

| Business Need | Wrong Approach | Right Approach | Why |
|---------------|----------------|----------------|-----|
| Send personalized email | Multi-agent content team | Single prompt with template | One-shot generation, no decisions needed |
| Categorize support tickets | Rule-based if/else | Single prompt classifier | Nuanced judgment, but simple output |
| Research competitor pricing | Single web scraper | Prompt chain with verification | Multiple steps, but sequential |
| Handle customer refunds | Static chatbot script | Tool-using agent | Dynamic decisions, tool access needed |
| Produce weekly newsletter | Single "do everything" agent | Multi-agent pipeline | Parallel work, specialized roles |

### Warning Signs of Over-Engineering

You're probably over-engineering if:

1. **Your agent mostly follows the same path** → Use a chain instead
2. **You're building "just in case" capability** → YAGNI (You Aren't Gonna Need It)
3. **Simple prompts solve 90% of cases** → Handle the 10% separately
4. **You can't explain why you need agents** → You probably don't
5. **Debugging takes longer than the task** → Reduce complexity

### When Agents ARE the Right Choice

Agents earn their complexity when you have:

- **Dynamic tool selection**: Different inputs require different tools
- **Uncertain path length**: Can't predict steps needed upfront
- **Real-time adaptation**: Must respond to external changes
- **Autonomous operation**: Runs without human guidance
- **Complex reasoning chains**: Multi-step logic with branching

---

## HOW to Apply This

### Exercise: Classify These Problems

For each scenario, identify:
1. Sharp-edged or rough-edged?
2. What level on the solution spectrum?
3. Why that level (not higher or lower)?

**Scenarios:**

1. Generate weekly social media posts from blog content
2. Route incoming emails to the right department
3. Create personalized workout plans based on user goals
4. Validate that uploaded invoices match purchase orders
5. Research and summarize industry news for executives
6. Answer employee questions about HR policies
7. Generate code documentation from source files
8. Orchestrate a hiring pipeline (screen, interview, assess)
9. Translate product descriptions to 5 languages
10. Monitor competitor pricing and alert on changes

### The Complexity Audit

Before your next AI project, ask:

1. **What's the simplest solution that could work?**
2. **What specific capability requires the next complexity level?**
3. **Can I defer that capability until proven necessary?**
4. **What's my fallback if the complex approach fails?**

:::checklist[complexity-audit]
- [ ] I can describe the problem without mentioning tools
- [ ] I've considered non-AI solutions first
- [ ] I can justify each complexity level I'm adding
- [ ] I have a simpler fallback if this approach fails
- [ ] The complexity matches the problem, not my ambition
:::

---

## Key Takeaways

1. **Start at Level 0** and only add complexity when forced
2. **Sharp-edged problems** often don't need AI—code works better
3. **Rough-edged problems** are AI's strength, but start simple
4. **80% of use cases** need prompts or chains, not agents
5. **Match complexity to problem**, not to what's technically possible

The best AI operators know when NOT to use agents.
