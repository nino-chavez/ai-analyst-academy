---
id: "5.3-project-scoping-estimation"
title: "Project Scoping & Estimation"
phase: 5
module: 3
estimatedMinutes: 15
concepts:
  - project-scoping
  - effort-estimation
  - delivery-phases
  - risk-buffers
bloomLevel: "apply"
---

# Project Scoping & Estimation

## WHY This Matters

AI projects fail more often from poor scoping than poor technology:

- Scope creep kills more pilots than hallucinations
- Under-estimation destroys credibility
- Over-estimation wastes resources and patience
- Unclear deliverables breed confusion and blame

The operators who deliver don't just understand AI—they understand how to structure work that succeeds.

---

## WHAT You Need to Know

### The AI Project Anatomy

:::concept[project-structure]
Every AI project has five phases, regardless of size:

**Phase 1: Foundation (10-15% of effort)**
- Solution architecture
- Data assessment
- Access and permissions
- Stakeholder alignment
- Success metrics definition

**Phase 2: Data & Infrastructure (20-30% of effort)**
- Data pipeline setup
- Storage and processing
- Model/API integration
- Security controls
- Testing environment

**Phase 3: Core Development (25-35% of effort)**
- Prompt engineering
- Workflow implementation
- Integration development
- Initial testing

**Phase 4: Validation & Tuning (15-20% of effort)**
- Quality evaluation
- Performance optimization
- User acceptance testing
- Edge case handling

**Phase 5: Deployment & Handoff (10-15% of effort)**
- Production deployment
- Documentation
- Training
- Knowledge transfer
- Monitoring setup
:::

### The Estimation Framework

**Step 1: Decompose the Work**

Break every deliverable into components:

```
DELIVERABLE: AI-Powered Customer Inquiry Triage

├─> Data Pipeline
│   ├─> Connect to ticketing system API
│   ├─> Extract and transform inquiry data
│   ├─> Store in vector database
│   └─> Set up refresh schedule

├─> AI Classification
│   ├─> Design category taxonomy
│   ├─> Develop classification prompts
│   ├─> Build retrieval chain
│   └─> Test and tune accuracy

├─> Integration
│   ├─> API for real-time classification
│   ├─> Dashboard integration
│   └─> Alert/routing logic

├─> Measurement
│   ├─> Accuracy tracking
│   ├─> Performance dashboards
│   └─> Feedback loop

└─> Handoff
    ├─> Documentation
    ├─> Training
    └─> Runbooks
```

**Step 2: Estimate Each Component**

For each component, estimate:

| Component | Optimistic | Most Likely | Pessimistic |
|-----------|:----------:|:-----------:|:-----------:|
| Ticketing API integration | 8 hrs | 16 hrs | 32 hrs |
| Data extraction | 4 hrs | 8 hrs | 16 hrs |
| Vector DB setup | 4 hrs | 8 hrs | 12 hrs |
| Category taxonomy | 4 hrs | 8 hrs | 16 hrs |
| Classification prompts | 8 hrs | 16 hrs | 32 hrs |
| ... | ... | ... | ... |

**Step 3: Apply the PERT Formula**

```
Estimate = (Optimistic + 4×Most Likely + Pessimistic) / 6
```

This weights toward "most likely" while accounting for uncertainty.

**Step 4: Add Buffers**

| Project Type | Buffer |
|--------------|--------|
| Well-understood domain, proven approach | 15-20% |
| Familiar domain, new AI application | 25-30% |
| New domain, experimental approach | 40-50% |

### The Staffing Model

Real project plans require roles with responsibilities:

**Example from enterprise AI project:**

| Role | Responsibilities | Typical Allocation |
|------|------------------|-------------------|
| **Lead Architect** | Solution design, technical decisions, quality oversight | 30-40% through project |
| **AI Engineer** | Infrastructure, model integration, prompt development | 60-80% during build phases |
| **Project Manager** | Coordination, status, risk management | 20-30% through project |
| **Domain Expert** | Requirements, data interpretation, validation | 10-20% peaks during phases 1, 4 |
| **Data Engineer** | Pipeline development, data quality | 50-70% during data phases |

**Critical insight**: AI projects need more architecture and less pure development than traditional software. The AI does the heavy lifting; humans design and validate.

### The Delivery Plan Structure

:::concept[delivery-plan]
**A complete delivery plan includes:**

**1. Executive Summary**
- Investment and timeline
- Key deliverables
- Success metrics
- Team structure

**2. Solution Overview**
- Architecture diagram
- Technology stack
- Integration points
- Ownership model

**3. Phased Timeline**
- Week-by-week breakdown
- Milestones and checkpoints
- Dependencies
- Risk points

**4. Staffing Plan**
- Roles and hours
- Skills required
- Availability assumptions

**5. Deliverables Matrix**
- What will be delivered
- Who owns each deliverable
- Quality criteria

**6. Success Metrics**
- How success will be measured
- Target thresholds
- Measurement approach

**7. Risk Management**
- Technical risks
- Operational risks
- Mitigation strategies

**8. Assumptions & Dependencies**
- What must be true
- External dependencies
- Decision points
:::

### The Scope Triangle for AI

Traditional: Pick two of (Fast, Good, Cheap)

For AI: Pick two of (Fast, Accurate, General)

| Trade-off | What It Means |
|-----------|---------------|
| Fast + Accurate | Narrow use case, well-defined scope |
| Fast + General | Accept lower accuracy, iterate later |
| Accurate + General | Takes longer, more training data/tuning |

**Most AI projects should optimize for Fast + Accurate (narrow scope).**

General-purpose AI solutions require exponentially more effort. Start narrow, prove value, expand.

### Common Scope Risks

| Risk | Indicator | Mitigation |
|------|-----------|------------|
| **Scope creep** | "Can we also add...?" | Change control process, scope freeze dates |
| **Data quality surprise** | Data is messier than expected | Early data audit, buffer for cleanup |
| **Integration complexity** | APIs don't work as documented | Spike early, integration testing |
| **Stakeholder availability** | Can't get decisions/reviews | Identify backups, schedule in advance |
| **Model performance** | AI doesn't perform as hoped | Clear go/no-go criteria, pivot options |
| **Security/compliance delay** | Review takes longer than expected | Engage early, don't surprise security team |

---

## HOW to Apply This

### Exercise: Scope an AI Project

:::exercise[project-scoping]
**Scenario**: You're asked to scope an AI project to help your merchandising team analyze customer reviews to identify product improvement opportunities.

**Requirements:**
- Ingest reviews from 3 e-commerce platforms (Amazon, your site, Walmart)
- Classify reviews by sentiment and topic (quality, fit, shipping, etc.)
- Surface top improvement opportunities weekly
- Integration with product management dashboard

**Create your project scope:**

**1. Decompose the Work**
- What are the major deliverables?
- What are the components of each deliverable?

**2. Estimate Each Component**
- Optimistic / Most Likely / Pessimistic hours
- Apply PERT formula

**3. Define Phases and Timeline**
- What's the logical sequence?
- What are the milestones?
- What's the total duration?

**4. Identify Staffing Needs**
- What roles are needed?
- At what allocation?

**5. List Assumptions and Risks**
- What must be true for this to work?
- What could go wrong?

**6. Define Success Metrics**
- How will you measure success?
- What's the minimum viable outcome?
:::

### The One-Page Project Scope

```
AI PROJECT SCOPE: [Project Name]

SUMMARY
- Duration: [X weeks]
- Investment: [Hours or $]
- Team: [Roles]
- Deliverable: [One sentence]

WHAT WE'RE BUILDING
[2-3 sentence description]

WHAT WE'RE NOT BUILDING
- [Explicit exclusion 1]
- [Explicit exclusion 2]

PHASES
Phase 1: [Name] - Week [X-Y]
  └─> Deliverables: [list]

Phase 2: [Name] - Week [X-Y]
  └─> Deliverables: [list]

[etc.]

SUCCESS LOOKS LIKE
- [Metric 1]: [Target]
- [Metric 2]: [Target]

KEY RISKS
- [Risk 1]: [Mitigation]
- [Risk 2]: [Mitigation]

ASSUMPTIONS
- [What must be true]

DEPENDENCIES
- [What we need from others]
```

### Estimation Calibration

Over time, track your estimates vs. actuals:

| Project | Estimated | Actual | Variance | Cause |
|---------|:---------:|:------:|:--------:|-------|
| Inquiry Triage | 240 hrs | 310 hrs | +29% | Data quality issues |
| Review Analysis | 160 hrs | 145 hrs | -9% | API easier than expected |
| Document Search | 120 hrs | 280 hrs | +133% | Scope creep |

**Use this data to:**
- Improve future estimates
- Identify systematic biases
- Build better buffers
- Learn from scope creep patterns

### Self-Check

:::checklist[module-5.3-complete]
- [ ] I can decompose AI projects into phases and components
- [ ] I understand the PERT estimation formula
- [ ] I know how to apply appropriate buffers
- [ ] I can structure a complete delivery plan
- [ ] I understand AI-specific scope risks
- [ ] I can create a one-page project scope
:::

---

## Up Next

In **Module 5.4: Stakeholder Communication**, you'll learn how to communicate progress, manage expectations, and handle difficult conversations when AI projects hit inevitable bumps.
